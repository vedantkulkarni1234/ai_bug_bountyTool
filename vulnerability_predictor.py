"""
Vulnerability Predictor Module

A security assessment tool that uses AI models to predict potential vulnerabilities
in web endpoints. Designed for legitimate security testing and code review purposes.
"""

import json
import re
import urllib.parse
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import hashlib
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class VulnerabilityPrediction:
    """Data class for vulnerability prediction results"""
    endpoint: str
    vulnerability_type: str
    confidence_score: float
    risk_level: str
    description: str
    recommendations: List[str]

class VulnerabilityPredictor:
    """
    Predicts potential vulnerabilities in web endpoints using AI models.
    Works entirely offline without external API calls.
    """
    
    def __init__(self, model_path: Optional[str] = None):
        """
        Initialize the vulnerability predictor.
        
        Args:
            model_path: Path to the trained AI model file (optional)
        """
        self.model = None
        self.vulnerability_patterns = self._load_vulnerability_patterns()
        self.risk_thresholds = {
            'low': 0.3,
            'medium': 0.6,
            'high': 0.8
        }
        
        if model_path:
            self.load_model(model_path)
        else:
            logger.warning("No model path provided. Using pattern-based analysis only.")
    
    def load_model(self, model_path: str) -> bool:
        """
        Load the trained AI model from file.
        
        Args:
            model_path: Path to the model file
            
        Returns:
            bool: True if model loaded successfully, False otherwise
        """
        try:
            # In a real implementation, this would load your actual AI model
            # For demonstration, we'll simulate model loading
            from ai_model import SecurityModel
            self.model = SecurityModel.load(model_path)
            logger.info(f"Model loaded successfully from {model_path}")
            return True
        except ImportError:
            logger.warning("ai_model module not available. Using fallback analysis.")
            self.model = None
            return False
        except Exception as e:
            logger.error(f"Failed to load model: {e}")
            self.model = None
            return False
    
    def _load_vulnerability_patterns(self) -> Dict[str, Dict]:
        """Load vulnerability detection patterns"""
        return {
            'sql_injection': {
                'patterns': [
                    r"['\"];?\s*(union|select|insert|update|delete|drop|alter)",
                    r"['\"]?\s*or\s+['\"]?1['\"]?\s*=\s*['\"]?1",
                    r"['\"]?\s*and\s+['\"]?1['\"]?\s*=\s*['\"]?1",
                    r"['\"]?\s*;\s*(exec|execute|sp_)",
                    r"['\"]?\s*--\s*",
                    r"/\*.*\*/"
                ],
                'weight': 0.8,
                'description': 'Potential SQL injection vulnerability detected'
            },
            'xss': {
                'patterns': [
                    r"<script[^>]*>.*?</script>",
                    r"javascript\s*:",
                    r"on(load|error|click|mouseover)\s*=",
                    r"<iframe[^>]*>",
                    r"<object[^>]*>",
                    r"eval\s*\(",
                    r"document\.(write|writeln|cookie)"
                ],
                'weight': 0.7,
                'description': 'Potential Cross-Site Scripting (XSS) vulnerability detected'
            },
            'path_traversal': {
                'patterns': [
                    r"\.\./+",
                    r"\.\.\\+",
                    r"%2e%2e%2f",
                    r"%2e%2e%5c",
                    r"\.\.%252f",
                    r"file://",
                    r"/etc/passwd",
                    r"\\windows\\system32"
                ],
                'weight': 0.6,
                'description': 'Potential path traversal vulnerability detected'
            },
            'command_injection': {
                'patterns': [
                    r";\s*(rm|del|format|shutdown|reboot)",
                    r"\|\s*(rm|del|format|cat|type)",
                    r"&&\s*(rm|del|format)",
                    r"`[^`]*`",
                    r"\$\([^)]*\)",
                    r">\s*/dev/null",
                    r"2>&1"
                ],
                'weight': 0.9,
                'description': 'Potential command injection vulnerability detected'
            },
            'ldap_injection': {
                'patterns': [
                    r"\(\s*\|\s*\(",
                    r"\)\s*\(\s*\|",
                    r"\*\s*\)\s*\(",
                    r"uid\s*=\s*\*",
                    r"cn\s*=\s*\*"
                ],
                'weight': 0.5,
                'description': 'Potential LDAP injection vulnerability detected'
            }
        }
    
    def extract_features(self, url: str, parameters: Dict[str, Any], 
                        request_body: Optional[str] = None) -> Dict[str, Any]:
        """
        Extract features from the request data for AI model input.
        
        Args:
            url: The target URL
            parameters: Request parameters
            request_body: Request body content
            
        Returns:
            Dict containing extracted features
        """
        features = {
            'url_length': len(url),
            'param_count': len(parameters),
            'has_file_extension': bool(re.search(r'\.[a-zA-Z]{2,4}$', url)),
            'has_query_string': '?' in url,
            'suspicious_keywords': 0,
            'special_chars': 0,
            'entropy': 0.0
        }
        
        # Analyze URL structure
        parsed_url = urllib.parse.urlparse(url)
        features['path_depth'] = len([p for p in parsed_url.path.split('/') if p])
        
        # Combine all input text for analysis
        all_text = f"{url} {' '.join(map(str, parameters.values()))}"
        if request_body:
            all_text += f" {request_body}"
        
        # Count suspicious keywords
        suspicious_keywords = [
            'admin', 'login', 'password', 'user', 'auth', 'session',
            'exec', 'eval', 'system', 'cmd', 'shell', 'script'
        ]
        features['suspicious_keywords'] = sum(
            1 for keyword in suspicious_keywords 
            if keyword.lower() in all_text.lower()
        )
        
        # Count special characters
        special_chars = set('<>"\';(){}[]|&*%$#@!`~')
        features['special_chars'] = sum(1 for char in all_text if char in special_chars)
        
        # Calculate entropy (measure of randomness)
        features['entropy'] = self._calculate_entropy(all_text)
        
        return features
    
    def _calculate_entropy(self, text: str) -> float:
        """Calculate Shannon entropy of text"""
        if not text:
            return 0.0
        
        # Count character frequencies
        char_counts = {}
        for char in text:
            char_counts[char] = char_counts.get(char, 0) + 1
        
        # Calculate entropy
        text_len = len(text)
        entropy = 0.0
        for count in char_counts.values():
            prob = count / text_len
            if prob > 0:
                entropy -= prob * (prob.bit_length() - 1)
        
        return entropy
    
    def pattern_based_analysis(self, url: str, parameters: Dict[str, Any], 
                             request_body: Optional[str] = None) -> List[Tuple[str, float]]:
        """
        Perform pattern-based vulnerability analysis.
        
        Args:
            url: The target URL
            parameters: Request parameters
            request_body: Request body content
            
        Returns:
            List of tuples containing (vulnerability_type, confidence_score)
        """
        results = []
        
        # Combine all input for pattern matching
        all_input = f"{url} {' '.join(map(str, parameters.values()))}"
        if request_body:
            all_input += f" {request_body}"
        
        for vuln_type, config in self.vulnerability_patterns.items():
            max_confidence = 0.0
            pattern_matches = 0
            
            for pattern in config['patterns']:
                matches = re.findall(pattern, all_input, re.IGNORECASE | re.DOTALL)
                if matches:
                    pattern_matches += len(matches)
            
            if pattern_matches > 0:
                # Calculate confidence based on number of matches and pattern weight
                raw_confidence = min(pattern_matches * 0.2, 1.0) * config['weight']
                max_confidence = max(max_confidence, raw_confidence)
            
            if max_confidence > 0.1:  # Minimum threshold
                results.append((vuln_type, max_confidence))
        
        return results
    
    def ai_model_analysis(self, features: Dict[str, Any]) -> List[Tuple[str, float]]:
        """
        Use AI model to predict vulnerabilities.
        
        Args:
            features: Extracted features from the request
            
        Returns:
            List of tuples containing (vulnerability_type, confidence_score)
        """
        if not self.model:
            return []
        
        try:
            # Use the AI model to make predictions
            predictions = self.model.predict(features)
            return predictions
        except Exception as e:
            logger.error(f"AI model prediction failed: {e}")
            return []
    
    def _determine_risk_level(self, confidence: float) -> str:
        """Determine risk level based on confidence score"""
        if confidence >= self.risk_thresholds['high']:
            return 'high'
        elif confidence >= self.risk_thresholds['medium']:
            return 'medium'
        elif confidence >= self.risk_thresholds['low']:
            return 'low'
        else:
            return 'minimal'
    
    def _get_recommendations(self, vulnerability_type: str) -> List[str]:
        """Get security recommendations for a vulnerability type"""
        recommendations = {
            'sql_injection': [
                'Use parameterized queries or prepared statements',
                'Implement input validation and sanitization',
                'Use stored procedures with proper parameter handling',
                'Apply principle of least privilege to database accounts'
            ],
            'xss': [
                'Implement proper output encoding/escaping',
                'Use Content Security Policy (CSP) headers',
                'Validate and sanitize all user inputs',
                'Use safe APIs that automatically escape content'
            ],
            'path_traversal': [
                'Validate and sanitize file paths',
                'Use whitelisting for allowed file access',
                'Implement proper access controls',
                'Avoid direct user input in file operations'
            ],
            'command_injection': [
                'Avoid system calls with user input',
                'Use safe APIs instead of shell commands',
                'Implement strict input validation',
                'Use parameterized commands when possible'
            ],
            'ldap_injection': [
                'Use parameterized LDAP queries',
                'Implement proper input validation',
                'Escape special LDAP characters',
                'Use authentication frameworks instead of custom LDAP queries'
            ]
        }
        
        return recommendations.get(vulnerability_type, [
            'Implement proper input validation',
            'Follow secure coding practices',
            'Regular security testing and code review'
        ])
    
    def predict_vulnerabilities(self, url: str, parameters: Dict[str, Any] = None, 
                              request_body: Optional[str] = None) -> Dict[str, Any]:
        """
        Predict vulnerabilities for a given endpoint.
        
        Args:
            url: The target URL
            parameters: Request parameters (default: empty dict)
            request_body: Request body content (optional)
            
        Returns:
            Dict containing prediction results in JSON format
        """
        if parameters is None:
            parameters = {}
        
        logger.info(f"Analyzing endpoint: {url}")
        
        # Extract features for AI model
        features = self.extract_features(url, parameters, request_body)
        
        # Perform pattern-based analysis
        pattern_results = self.pattern_based_analysis(url, parameters, request_body)
        
        # Perform AI model analysis
        ai_results = self.ai_model_analysis(features)
        
        # Combine results from both methods
        combined_results = {}
        
        # Add pattern-based results
        for vuln_type, confidence in pattern_results:
            combined_results[vuln_type] = confidence
        
        # Add AI model results (with higher weight if available)
        for vuln_type, confidence in ai_results:
            if vuln_type in combined_results:
                # Average the scores with AI model having higher weight
                combined_results[vuln_type] = (
                    combined_results[vuln_type] * 0.3 + confidence * 0.7
                )
            else:
                combined_results[vuln_type] = confidence
        
        # Create predictions list
        predictions = []
        for vuln_type, confidence in combined_results.items():
            risk_level = self._determine_risk_level(confidence)
            description = self.vulnerability_patterns.get(
                vuln_type, {}
            ).get('description', f'Potential {vuln_type} vulnerability detected')
            
            prediction = VulnerabilityPrediction(
                endpoint=url,
                vulnerability_type=vuln_type,
                confidence_score=round(confidence, 3),
                risk_level=risk_level,
                description=description,
                recommendations=self._get_recommendations(vuln_type)
            )
            predictions.append(prediction)
        
        # Sort by confidence score (highest first)
        predictions.sort(key=lambda x: x.confidence_score, reverse=True)
        
        # Create response
        response = {
            'endpoint': url,
            'timestamp': self._get_timestamp(),
            'analysis_summary': {
                'total_vulnerabilities_found': len(predictions),
                'highest_risk_level': predictions[0].risk_level if predictions else 'none',
                'analysis_methods': ['pattern_based'] + (['ai_model'] if self.model else [])
            },
            'predictions': [
                {
                    'vulnerability_type': p.vulnerability_type,
                    'confidence_score': p.confidence_score,
                    'risk_level': p.risk_level,
                    'description': p.description,
                    'recommendations': p.recommendations
                }
                for p in predictions
            ],
            'request_analysis': {
                'features_extracted': features,
                'parameters_analyzed': len(parameters),
                'has_request_body': request_body is not None
            }
        }
        
        return response
    
    def batch_predict(self, endpoints: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Perform batch prediction on multiple endpoints.
        
        Args:
            endpoints: List of endpoint dictionaries with 'url', 'parameters', 'request_body'
            
        Returns:
            List of prediction results
        """
        results = []
        
        for i, endpoint in enumerate(endpoints):
            logger.info(f"Processing endpoint {i+1}/{len(endpoints)}")
            
            url = endpoint.get('url', '')
            parameters = endpoint.get('parameters', {})
            request_body = endpoint.get('request_body')
            
            try:
                result = self.predict_vulnerabilities(url, parameters, request_body)
                results.append(result)
            except Exception as e:
                logger.error(f"Failed to analyze endpoint {url}: {e}")
                results.append({
                    'endpoint': url,
                    'error': str(e),
                    'predictions': []
                })
        
        return results
    
    def export_results(self, results: Dict[str, Any], filename: str) -> bool:
        """
        Export results to JSON file.
        
        Args:
            results: Prediction results
            filename: Output filename
            
        Returns:
            bool: True if export successful, False otherwise
        """
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            logger.info(f"Results exported to {filename}")
            return True
        except Exception as e:
            logger.error(f"Failed to export results: {e}")
            return False
    
    def _get_timestamp(self) -> str:
        """Get current timestamp string"""
        from datetime import datetime
        return datetime.now().isoformat()

# Example usage and testing
def main():
    """Example usage of the VulnerabilityPredictor"""
    
    # Initialize predictor
    predictor = VulnerabilityPredictor()
    
    # Example 1: Basic URL analysis
    test_url = "https://example.com/login.php"
    test_params = {
        'username': 'admin',
        'password': "' OR '1'='1' --",
        'action': 'login'
    }
    
    print("=== Single Endpoint Analysis ===")
    result = predictor.predict_vulnerabilities(test_url, test_params)
    print(json.dumps(result, indent=2))
    
    # Example 2: Batch analysis
    endpoints = [
        {
            'url': 'https://example.com/search.php',
            'parameters': {'q': '<script>alert("xss")</script>'},
            'request_body': None
        },
        {
            'url': 'https://example.com/file.php',
            'parameters': {'file': '../../../etc/passwd'},
            'request_body': None
        },
        {
            'url': 'https://example.com/api/users',
            'parameters': {},
            'request_body': '{"id": "1; DROP TABLE users;--"}'
        }
    ]
    
    print("\n=== Batch Analysis ===")
    batch_results = predictor.batch_predict(endpoints)
    
    for i, result in enumerate(batch_results):
        print(f"\nEndpoint {i+1}: {result['endpoint']}")
        print(f"Vulnerabilities found: {result['analysis_summary']['total_vulnerabilities_found']}")
        if result['predictions']:
            highest_risk = result['predictions'][0]
            print(f"Highest risk: {highest_risk['vulnerability_type']} "
                  f"(confidence: {highest_risk['confidence_score']}, "
                  f"risk: {highest_risk['risk_level']})")

if __name__ == "__main__":
    main()